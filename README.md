# Adversarial Attacks
This repository will show various adversarial perturbations for white-box attacks on classification datasets. For my own practice and satsifaction.
See `attack_showcase.ipynb` for examples.
This will include:

[1]
Ian J. Goodfellow, Jonathon Shlens, & Christian Szegedy. (2014). Explaining and Harnessing Adversarial Examples.

[2]
Nicolas Papernot, Patrick McDaniel, Somesh Jha, Matt Fredrikson, Z. Berkay Celik, & Ananthram Swami. (2015). The Limitations of Deep Learning in Adversarial Settings.

